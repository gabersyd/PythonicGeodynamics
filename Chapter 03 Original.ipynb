{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How fast is your Computing Machine?\n",
    "\n",
    "Our computers do basically two things, one is storing numbers, the other is doing mathematical operations on them. They are so useful because they do these things extraordinarily fast and extraordinarily well, in the sense that they always do it correctly following our instructions. For this reason the main way in which we use them is to give them repetitive instructions for up to billions of times.\n",
    "\n",
    "Since the speed of the CPU has duplicated ever 1.5 years until few years ago (Moore’s Law), we may have lost track of how really fast is the computer in our hands. When starting this journey into numerical modeling, it is important to first quickly experiment this and realize how remarkably fast it really is, but also to perceive its limits when we reach it.\n",
    "\n",
    "In this chapter, we start using iPython because its interactive setting allows us feeling better what the computer does. Later we will step into writing and running a program. Let us initially load NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# this function simply counts from 0 to max\n",
    "def count(max):\n",
    "    i=0\n",
    "    while i<max:\n",
    "        i=i+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.36 ms ± 81.4 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit count(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62.2 ms ± 680 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit count(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "639 ms ± 9.16 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit count(10000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# also this function counts, but increasingly larger numbers\n",
    "def addCount(max):\n",
    "    a=0.0\n",
    "    for i in range(max):\n",
    "        a=a+i\n",
    "    #print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When I try to launch count(1000) or count(100000) on my laptop I simply do not observe any difference. Just the time to call the function, and I get the result. It is unnoticeable that the second call required 100 times more calculation than the first one. Only when I arrive at one million or better ten millions, I finally observe a lag. In fact what I notice is the time that it takes to one processor of my laptop for this serial calculation. You can test yours and perceive the power of your computer.\n",
    "\n",
    "We can be also more quantitative about the time required by our little routine. iPython offers a very simple and powerful magic command called %timeit. Let us test it for testing the time required by our loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.56 ms ± 97.6 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit addCount(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.6 ms ± 1.05 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit addCount(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "655 ms ± 9.48 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit addCount(10000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let's focus the Numerical Tools of Python. Among others, NumPy adds to standard Python the following features:\n",
    "    A. Multidimensional vectorized arrays\n",
    "    B. Mathematical functions operating on an array or portions of it\n",
    "    C. Linear Algebra, Fourier development, Random Functions\n",
    "    D. Input/Output functions to efficiently create and read memory mapped files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy Types\n",
    "\n",
    "Without any further specification, Python automatically uses float type machine precision. We might not know which precision this is, in which case it is important to discover it. A very straightforward way to discover the precision of our machine is by testing for which small ε, a and a + ε become indistinguishable. We can do so by iteratively decreasing ε of a certain ratio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.0\n",
      "Precision: 0.1111111111111111\n",
      "Precision: 0.012345679012345678\n",
      "Precision: 0.0013717421124828531\n",
      "Precision: 0.00015241579027587256\n",
      "Precision: 1.6935087808430286e-05\n",
      "Precision: 1.8816764231589206e-06\n",
      "Precision: 2.0907515812876894e-07\n",
      "Precision: 2.323057312541877e-08\n",
      "Precision: 2.5811747917131966e-09\n",
      "Precision: 2.867971990792441e-10\n",
      "Precision: 3.1866355453249343e-11\n",
      "Precision: 3.5407061614721493e-12\n",
      "Precision: 3.934117957191277e-13\n",
      "Precision: 4.371242174656974e-14\n",
      "Precision: 4.85693574961886e-15\n",
      "Precision: 5.396595277354289e-16\n",
      "Precision: 5.996216974838099e-17\n",
      "Precision: 6.6624633053756655e-18\n",
      "Precision: 7.402737005972962e-19\n",
      "Precision: 8.225263339969957e-20\n",
      "Precision: 9.139181488855508e-21\n",
      "Precision: 1.0154646098728343e-21\n",
      "Precision: 1.1282940109698158e-22\n",
      "Precision: 1.2536600121886843e-23\n",
      "Precision: 1.392955569098538e-24\n",
      "Precision: 1.5477284101094868e-25\n",
      "Precision: 1.7196982334549854e-26\n",
      "Precision: 1.9107758149499837e-27\n",
      "Precision: 2.1230842388333153e-28\n",
      "Precision: 2.3589824875925725e-29\n",
      "Precision: 2.621091652880636e-30\n",
      "Precision: 2.9123240587562624e-31\n",
      "Precision: 3.2359156208402915e-32\n",
      "Precision: 3.595461800933657e-33\n",
      "Precision: 3.994957556592953e-34\n",
      "Precision: 4.4388417295477253e-35\n",
      "Precision: 4.932046366164139e-36\n",
      "Precision: 5.480051517960155e-37\n",
      "Precision: 6.088946131066838e-38\n",
      "Precision: 6.765495701185375e-39\n",
      "Precision: 7.517217445761529e-40\n",
      "Precision: 8.352463828623921e-41\n",
      "Precision: 9.28051536513769e-42\n",
      "Precision: 1.0311683739041878e-42\n",
      "Precision: 1.1457426376713199e-43\n",
      "Precision: 1.2730473751903554e-44\n",
      "Precision: 1.4144970835448395e-45\n",
      "Precision: 1.5716634261609329e-46\n",
      "Precision: 1.74629269573437e-47\n",
      "Precision: 1.9403252174826334e-48\n",
      "Precision: 2.155916908314037e-49\n",
      "Precision: 2.395463231460041e-50\n",
      "Precision: 2.6616258127333788e-51\n",
      "Precision: 2.9573620141481986e-52\n",
      "Precision: 3.2859577934979986e-53\n",
      "Precision: 3.651064214997776e-54\n",
      "Precision: 4.056738016664196e-55\n",
      "Precision: 4.50748668518244e-56\n",
      "Precision: 5.0083185390916e-57\n",
      "Precision: 5.5647983767684445e-58\n",
      "Precision: 6.183109307520494e-59\n",
      "Precision: 6.870121452800549e-60\n",
      "Precision: 7.633468280889499e-61\n",
      "Precision: 8.481631423210554e-62\n",
      "Precision: 9.424034914678393e-63\n",
      "Precision: 1.0471149905198215e-63\n",
      "Precision: 1.1634611005775795e-64\n",
      "Precision: 1.2927345561973105e-65\n",
      "Precision: 1.4363717291081228e-66\n",
      "Precision: 1.5959685878979142e-67\n",
      "Precision: 1.7732984309976824e-68\n",
      "Precision: 1.970331589997425e-69\n",
      "Precision: 2.1892573222193612e-70\n",
      "Precision: 2.4325081357992902e-71\n",
      "Precision: 2.702786817554767e-72\n",
      "Precision: 3.003096463949741e-73\n",
      "Precision: 3.3367738488330452e-74\n",
      "Precision: 3.7075264987033837e-75\n",
      "Precision: 4.1194738874482043e-76\n",
      "Precision: 4.5771932082757826e-77\n",
      "Precision: 5.085770231417536e-78\n",
      "Precision: 5.650855812686151e-79\n",
      "Precision: 6.27872868076239e-80\n",
      "Precision: 6.9763652008471e-81\n",
      "Precision: 7.751516889830111e-82\n",
      "Precision: 8.612796544255678e-83\n",
      "Precision: 9.569773938061865e-84\n",
      "Precision: 1.0633082153402071e-84\n",
      "Precision: 1.1814535726002301e-85\n",
      "Precision: 1.3127261917780335e-86\n",
      "Precision: 1.4585846575311483e-87\n",
      "Precision: 1.6206496194790536e-88\n",
      "Precision: 1.8007217994211708e-89\n",
      "Precision: 2.0008019993568564e-90\n",
      "Precision: 2.2231133326187293e-91\n",
      "Precision: 2.4701259251319215e-92\n",
      "Precision: 2.7445843612576906e-93\n",
      "Precision: 3.049538179175212e-94\n",
      "Precision: 3.388375754639125e-95\n",
      "Precision: 3.764861949599027e-96\n",
      "Precision: 4.183179943998919e-97\n",
      "Precision: 4.6479777155543544e-98\n",
      "Precision: 5.164419683949283e-99\n",
      "Precision: 5.738244093276981e-100\n",
      "Precision: 6.375826770307757e-101\n",
      "Precision: 7.084251967008619e-102\n",
      "Precision: 7.871391074454021e-103\n",
      "Precision: 8.74599008272669e-104\n",
      "Precision: 9.717766758585212e-105\n",
      "Precision: 1.0797518620650235e-105\n",
      "Precision: 1.1997242911833593e-106\n",
      "Precision: 1.3330269902037326e-107\n",
      "Precision: 1.4811411002263697e-108\n",
      "Precision: 1.6457123335848551e-109\n",
      "Precision: 1.828569259538728e-110\n",
      "Precision: 2.0317436217096978e-111\n",
      "Precision: 2.2574929130107753e-112\n",
      "Precision: 2.5083254589008614e-113\n",
      "Precision: 2.787028287667624e-114\n",
      "Precision: 3.096698097408471e-115\n",
      "Precision: 3.44077566378719e-116\n",
      "Precision: 3.823084070874656e-117\n",
      "Precision: 4.247871189860729e-118\n",
      "Precision: 4.7198568776230323e-119\n",
      "Precision: 5.244285419581147e-120\n",
      "Precision: 5.8269837995346075e-121\n",
      "Precision: 6.474426443927341e-122\n",
      "Precision: 7.193807159919269e-123\n",
      "Precision: 7.993119066576966e-124\n",
      "Precision: 8.88124340730774e-125\n",
      "Precision: 9.868048230341933e-126\n",
      "Precision: 1.096449803371326e-126\n",
      "Precision: 1.2182775593014733e-127\n",
      "Precision: 1.3536417325571926e-128\n",
      "Precision: 1.5040463695079916e-129\n",
      "Precision: 1.6711626327866573e-130\n",
      "Precision: 1.8568473697629525e-131\n",
      "Precision: 2.0631637441810583e-132\n",
      "Precision: 2.292404160201176e-133\n",
      "Precision: 2.5471157335568623e-134\n",
      "Precision: 2.830128592840958e-135\n",
      "Precision: 3.1445873253788422e-136\n",
      "Precision: 3.4939859170876023e-137\n",
      "Precision: 3.88220657454178e-138\n",
      "Precision: 4.3135628606019784e-139\n",
      "Precision: 4.792847622891088e-140\n",
      "Precision: 5.325386247656764e-141\n",
      "Precision: 5.917095830729738e-142\n",
      "Precision: 6.574550923033042e-143\n",
      "Precision: 7.305056581147824e-144\n",
      "Precision: 8.116729534608694e-145\n",
      "Precision: 9.018588371787438e-146\n",
      "Precision: 1.0020653746430487e-146\n",
      "Precision: 1.1134059718256097e-147\n",
      "Precision: 1.2371177464728997e-148\n",
      "Precision: 1.3745752738587775e-149\n",
      "Precision: 1.5273058598430862e-150\n",
      "Precision: 1.6970065109367624e-151\n",
      "Precision: 1.885562789929736e-152\n",
      "Precision: 2.0950697665885954e-153\n",
      "Precision: 2.3278552962095505e-154\n",
      "Precision: 2.5865058846772782e-155\n",
      "Precision: 2.873895427419198e-156\n",
      "Precision: 3.193217141576886e-157\n",
      "Precision: 3.54801904619654e-158\n",
      "Precision: 3.9422433846628226e-159\n",
      "Precision: 4.380270427403136e-160\n",
      "Precision: 4.8669671415590405e-161\n",
      "Precision: 5.407741268398934e-162\n",
      "Precision: 6.008601409332149e-163\n",
      "Precision: 6.6762237881468325e-164\n",
      "Precision: 7.418026431274259e-165\n",
      "Precision: 8.242251590304732e-166\n",
      "Precision: 9.158057322560813e-167\n",
      "Precision: 1.0175619247289793e-167\n",
      "Precision: 1.130624360809977e-168\n",
      "Precision: 1.2562492897888634e-169\n",
      "Precision: 1.3958325442098483e-170\n",
      "Precision: 1.5509250491220536e-171\n",
      "Precision: 1.7232500545800595e-172\n",
      "Precision: 1.9147222828667327e-173\n",
      "Precision: 2.1274692031852587e-174\n",
      "Precision: 2.363854670205843e-175\n",
      "Precision: 2.6265051891176034e-176\n",
      "Precision: 2.9183390990195595e-177\n",
      "Precision: 3.242598998910622e-178\n",
      "Precision: 3.602887776567358e-179\n",
      "Precision: 4.003208640630398e-180\n",
      "Precision: 4.448009600700442e-181\n",
      "Precision: 4.942232889667158e-182\n",
      "Precision: 5.491369877407954e-183\n",
      "Precision: 6.101522086008837e-184\n",
      "Precision: 6.779468984454264e-185\n",
      "Precision: 7.532743316060293e-186\n",
      "Precision: 8.369714795622548e-187\n",
      "Precision: 9.299683106247276e-188\n",
      "Precision: 1.0332981229163639e-188\n",
      "Precision: 1.1481090254626265e-189\n",
      "Precision: 1.275676694958474e-190\n",
      "Precision: 1.41741854995386e-191\n",
      "Precision: 1.5749094999487333e-192\n",
      "Precision: 1.7498994443874815e-193\n",
      "Precision: 1.9443327159860904e-194\n",
      "Precision: 2.160369684428989e-195\n",
      "Precision: 2.4004107604766547e-196\n",
      "Precision: 2.667123067196283e-197\n",
      "Precision: 2.9634700746625367e-198\n",
      "Precision: 3.2927445274028187e-199\n",
      "Precision: 3.6586050304475763e-200\n",
      "Precision: 4.065116700497307e-201\n",
      "Precision: 4.516796333885897e-202\n",
      "Precision: 5.018662593206552e-203\n",
      "Precision: 5.576291770229502e-204\n",
      "Precision: 6.195879744699447e-205\n",
      "Precision: 6.88431082744383e-206\n",
      "Precision: 7.649234252715366e-207\n",
      "Precision: 8.49914916968374e-208\n",
      "Precision: 9.443499077426378e-209\n",
      "Precision: 1.0492776752695976e-209\n",
      "Precision: 1.1658640836328863e-210\n",
      "Precision: 1.2954045373698738e-211\n",
      "Precision: 1.4393383748554154e-212\n",
      "Precision: 1.5992648609504617e-213\n",
      "Precision: 1.776960956611624e-214\n",
      "Precision: 1.9744010629018045e-215\n",
      "Precision: 2.1937789587797828e-216\n",
      "Precision: 2.437532176421981e-217\n",
      "Precision: 2.708369084913312e-218\n",
      "Precision: 3.009298983237013e-219\n",
      "Precision: 3.3436655369300148e-220\n",
      "Precision: 3.7151839299222385e-221\n",
      "Precision: 4.127982144358043e-222\n",
      "Precision: 4.586646827064493e-223\n",
      "Precision: 5.096274252293881e-224\n",
      "Precision: 5.662526946993201e-225\n",
      "Precision: 6.291696607770223e-226\n",
      "Precision: 6.990774008633581e-227\n",
      "Precision: 7.767526676259535e-228\n",
      "Precision: 8.630585195843928e-229\n",
      "Precision: 9.589539106493253e-230\n",
      "Precision: 1.065504345165917e-230\n",
      "Precision: 1.1838937168510189e-231\n",
      "Precision: 1.3154374631677987e-232\n",
      "Precision: 1.461597181297554e-233\n",
      "Precision: 1.6239968681083932e-234\n",
      "Precision: 1.8044409645648814e-235\n",
      "Precision: 2.0049344050720902e-236\n",
      "Precision: 2.2277048945245448e-237\n",
      "Precision: 2.4752276605828277e-238\n",
      "Precision: 2.750252956203142e-239\n",
      "Precision: 3.055836618003491e-240\n",
      "Precision: 3.3953740200038785e-241\n",
      "Precision: 3.772637800004309e-242\n",
      "Precision: 4.191819777782566e-243\n",
      "Precision: 4.6575775308695176e-244\n",
      "Precision: 5.175086145410575e-245\n",
      "Precision: 5.750095717122861e-246\n",
      "Precision: 6.388995241247624e-247\n",
      "Precision: 7.098883601386249e-248\n",
      "Precision: 7.887648445984721e-249\n",
      "Precision: 8.764053828871912e-250\n",
      "Precision: 9.737837587635458e-251\n",
      "Precision: 1.0819819541817174e-251\n",
      "Precision: 1.2022021713130193e-252\n",
      "Precision: 1.3357801903477992e-253\n",
      "Precision: 1.4842002114975546e-254\n",
      "Precision: 1.649111346108394e-255\n",
      "Precision: 1.8323459401204377e-256\n",
      "Precision: 2.035939933467153e-257\n",
      "Precision: 2.26215548163017e-258\n",
      "Precision: 2.5135060907001887e-259\n",
      "Precision: 2.792784545222432e-260\n",
      "Precision: 3.1030939391360357e-261\n",
      "Precision: 3.447882154595595e-262\n",
      "Precision: 3.830980171772884e-263\n",
      "Precision: 4.256644635303204e-264\n",
      "Precision: 4.729605150336893e-265\n",
      "Precision: 5.255116833707659e-266\n",
      "Precision: 5.839018704119621e-267\n",
      "Precision: 6.487798560132913e-268\n",
      "Precision: 7.208665066814347e-269\n",
      "Precision: 8.00962785201594e-270\n",
      "Precision: 8.899586502239934e-271\n",
      "Precision: 9.888429446933259e-272\n",
      "Precision: 1.0987143829925844e-272\n",
      "Precision: 1.2207937588806493e-273\n",
      "Precision: 1.3564375098673882e-274\n",
      "Precision: 1.5071527887415426e-275\n",
      "Precision: 1.674614209712825e-276\n",
      "Precision: 1.8606824552364721e-277\n",
      "Precision: 2.0674249502627467e-278\n",
      "Precision: 2.297138833625274e-279\n",
      "Precision: 2.55237648180586e-280\n",
      "Precision: 2.835973868673178e-281\n",
      "Precision: 3.1510820763035312e-282\n",
      "Precision: 3.5012023070039234e-283\n",
      "Precision: 3.890224785559915e-284\n",
      "Precision: 4.322471983955461e-285\n",
      "Precision: 4.8027466488394015e-286\n",
      "Precision: 5.336385165377113e-287\n",
      "Precision: 5.929316850419014e-288\n",
      "Precision: 6.588129833798905e-289\n",
      "Precision: 7.320144259776561e-290\n",
      "Precision: 8.133493621973957e-291\n",
      "Precision: 9.037215135526619e-292\n",
      "Precision: 1.004135015058513e-292\n",
      "Precision: 1.1157055722872368e-293\n",
      "Precision: 1.2396728580969298e-294\n",
      "Precision: 1.3774142867743663e-295\n",
      "Precision: 1.5304603186381847e-296\n",
      "Precision: 1.7005114651535384e-297\n",
      "Precision: 1.8894571835039315e-298\n",
      "Precision: 2.0993968705599237e-299\n",
      "Precision: 2.3326631895110265e-300\n",
      "Precision: 2.591847988345585e-301\n",
      "Precision: 2.879831098161761e-302\n",
      "Precision: 3.1998123312908456e-303\n",
      "Precision: 3.555347034767606e-304\n",
      "Precision: 3.9503855941862293e-305\n",
      "Precision: 4.389317326873588e-306\n",
      "Precision: 4.877019252081764e-307\n",
      "Precision: 5.418910280090849e-308\n",
      "Precision: 6.021011422323166e-309\n",
      "Precision: 6.6900126914702e-310\n",
      "Precision: 7.433347434967e-311\n",
      "Precision: 8.25927492774e-312\n",
      "Precision: 9.17697214195e-313\n",
      "Precision: 1.0196635713e-313\n",
      "Precision: 1.1329595237e-314\n",
      "Precision: 1.258843915e-315\n",
      "Precision: 1.39871546e-316\n",
      "Precision: 1.5541284e-317\n",
      "Precision: 1.72681e-318\n",
      "Precision: 1.91865e-319\n",
      "Precision: 2.132e-320\n",
      "Precision: 2.367e-321\n",
      "Precision: 2.6e-322\n",
      "Precision: 3e-323\n",
      "Precision: 5e-324\n"
     ]
    }
   ],
   "source": [
    "epsilon, ratio = 1.0, 9.0 \n",
    "while (epsilon):\n",
    "    print('Precision:',epsilon) \n",
    "    epsilon /= ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last line indicates that the precision that standard Python assumes on my machine is 10^{−324}. This is indeed associated to a 64-bit float number. One can verify this by setting a smaller precision in the first line of this sequence. Setting initially:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.0\n",
      "Precision: 0.111111\n",
      "Precision: 0.0123457\n",
      "Precision: 0.00137174\n",
      "Precision: 0.000152416\n",
      "Precision: 1.69351e-05\n",
      "Precision: 1.88168e-06\n",
      "Precision: 2.09075e-07\n",
      "Precision: 2.32306e-08\n",
      "Precision: 2.58117e-09\n",
      "Precision: 2.86797e-10\n",
      "Precision: 3.18664e-11\n",
      "Precision: 3.54071e-12\n",
      "Precision: 3.93412e-13\n",
      "Precision: 4.37124e-14\n",
      "Precision: 4.85694e-15\n",
      "Precision: 5.3966e-16\n",
      "Precision: 5.99622e-17\n",
      "Precision: 6.66246e-18\n",
      "Precision: 7.40274e-19\n",
      "Precision: 8.22526e-20\n",
      "Precision: 9.13918e-21\n",
      "Precision: 1.01546e-21\n",
      "Precision: 1.12829e-22\n",
      "Precision: 1.25366e-23\n",
      "Precision: 1.39296e-24\n",
      "Precision: 1.54773e-25\n",
      "Precision: 1.7197e-26\n",
      "Precision: 1.91078e-27\n",
      "Precision: 2.12308e-28\n",
      "Precision: 2.35898e-29\n",
      "Precision: 2.62109e-30\n",
      "Precision: 2.91232e-31\n",
      "Precision: 3.23592e-32\n",
      "Precision: 3.59546e-33\n",
      "Precision: 3.99496e-34\n",
      "Precision: 4.43884e-35\n",
      "Precision: 4.93205e-36\n",
      "Precision: 5.48005e-37\n",
      "Precision: 6.08895e-38\n",
      "Precision: 6.7655e-39\n",
      "Precision: 7.51722e-40\n",
      "Precision: 8.35244e-41\n",
      "Precision: 9.2808e-42\n",
      "Precision: 1.03136e-42\n",
      "Precision: 1.14906e-43\n",
      "Precision: 1.26117e-44\n",
      "Precision: 1.4013e-45\n"
     ]
    }
   ],
   "source": [
    "epsilon, ratio =  np.float16(1), np.float32(9)\n",
    "while (epsilon):\n",
    "    print('Precision:',epsilon) \n",
    "    epsilon /= ratio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to float, there exist integers with several precisions: np.int32, np.int64, np.int128. The type of every NumPy variable can be    retrieved the dtype, e.g., eps.dtype.\n",
    "\n",
    "It is very important to keep in mind the importance of precision. All the mathematical routines implemented in Python, as well as in any other language, follow the standards determined by IEEE which imply that they are all corrected to the last digit. Therefore, when we will model a physical system we can be sure that errors will not propagate quickly to lower digits with every algorithm that does not explicitly remove this information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ndarrays\n",
    "\n",
    "Let us start looking at the vectorized arrays. The core of NumPy is the object called ndarray, a storage of large quantities of data that allows to operate fast and flexible operations on it. Let’s look at some basic examples using iPython again and create a matrix (a two-dimensional array) of two rows and three columns:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int8')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstArr = np.array([[4,6,3,4],[2,3,6,0]], dtype=np.int8)\n",
    "firstArr.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstArr.ndim # number of dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 4)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstArr.shape # array shape as (rows,columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int8')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstArr.dtype # Out[10]: dtype(’int64’)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we find is that NumPy, if given a certain set of data, automatically decides a type (generally integer or float) and defines an array of the right shape where to store them. Given a NumPy array, it is always possible to obtain its shape and data type (dtype). The main difference between ndarrays and Python data types is that the elements of ndarrays are all of a predefined and homogeneous type, which is one of the reasons for the speed of its calculations.\n",
    "\n",
    "In general, one can set the data type at the moment of creation of the array, which is a particularly useful function when one has to handle very large models and datasets and needs to be in control of the size of the occupied memory. Data in NumPy are either int: integer, uint: unsigned integer (from 0), and float, a real number. int and uint can have sizes of 8, 16, 32, and 64 bits, while float of 16, 32, and 64 bits. If not otherwise set, automatically NumPy will set data type size to 64 bits.\n",
    "\n",
    "Most commonly used generators of ndarrays are arange, zeros and ones. Let us look at some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19], dtype=int32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "secondArr = np.arange((20),dtype=np.int32)\n",
    "secondArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int32')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "secondArr.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "In [14]: secondArr = np.zeros(20)\n",
    "In [15]: secondArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "In [16]: secondArr.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "In [17]: secondArr = np.ones(20)\n",
    "In [18]: secondArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "In [19]: secondArr.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "arange is the analogue of range in Python, but it creates a NumPy array of 64 bits integers. zeros and ones instead create arrays of 64 bits float. ones can also be created by zeros using the broadcasting properties of NumPy arrays, just by the instruction arr=np.zeros(20)+1.0. If we wish to create arrays with different types, for example due to operational reasons or of memory size, dtypes can be explicitly specified, \n",
    "e.g.,arr = np.arange(20, dtype=’float32’) or arr = np.ones(20, dtype=’int8’).\n",
    "\n",
    "Let us now check how using NumPy allows to speed the calculations of the prior section. The first temptation might be to simply to replace range with np.arange."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def addCountNP(max):\n",
    "    a=0\n",
    "    for i in np.arange(max):\n",
    "        a=a+i\n",
    "    #print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.21 s ± 350 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit addCountNP(10000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "655 ms ± 9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit addCount(10000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happened here is that although the arrays were ndarrays, the operation was done as for a standard Python list. The trick to speed calculations on ndarrays is to use the broadcast vectorized version of each operation. Let us look at how to add two ndarrays of one million of integers either with the standard Python loop and exploiting the NumPy broadcasting capabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def addArray(a,b):\n",
    "    c=np.zeros(a.size)\n",
    "    for i in np.arange(a.size):\n",
    "        c[i]=a[i]+b[i]\n",
    "    return(c)\n",
    "\n",
    "a=np.arange(1000000)\n",
    "b=np.arange(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "657 ms ± 481 µs per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit c=addArray(a,b) #standard python "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.45 ms ± 1.56 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit c=a+b #NumPy arrays broadcasting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A gain of two orders of magnitude! To use the broadcasting feature of NumPy makes Python’s speed comparable to compiled codes such as C, but with the obvious huge gain in terms for code development, testing, and readability. Broadcasting is clearly not limited to the addition operation, but it works as well with all the other arithmetic operations such as c=a*b; c=a/b; c=a-b,as well as scalar-array operations like \n",
    "```python \n",
    "c=1/a; \n",
    "c=a**0.5\n",
    "```\n",
    "Besides operations on two arrays, there are numerous unary (and binary universal functions that can be used with NumPy arrays. Among unary functions, much used ones are \n",
    "```python \n",
    "np.abs()\n",
    "np.sqrt()\n",
    "np.exp()\n",
    "np.log()\n",
    "np.sign()\n",
    "```\n",
    "and all the trigonometric functions. Binary functions are \n",
    "```python \n",
    "np.add()\n",
    "np.multiply()\n",
    "np.power()\n",
    "np.maximum()\n",
    "np.mod().\n",
    "```\n",
    "Let us go back now to the initial problem. We wanted to sum all the elements of a large array (100 millions numbers). This is neither an unary or binary operation, because it is a function that projects an array into one number, the sum. The most common among these operations are already efficiently implemented in NumPy. For example, the sum is immediately obtained by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.3 ms ± 10.4 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "%timeit np.arange(10000000).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.10048771  0.36563131  0.13362572 ...,  0.30150524  0.74721818\n",
      "  0.35012432]\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "x=np.random.rand(1001)\n",
    "print(x)\n",
    "g=1\n",
    "for y in x:\n",
    "     g = g*y\n",
    "print (g)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These operation have been in fact written in Cython, which is a C compiled operation. We will see later in this chapter how such operations, when not already implemented in NumPy, can be easily created using Cython."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing and Slicing\n",
    "\n",
    "Most languages today are compiled. One of the great features of compilers is that when we have to perform a set of repetitive operations on a large set of data the compiler will take care to optimize these iterations in an exceptional way, even if we wrote a very confusing code. This is not the case with an interpreted software like Python.\n",
    "\n",
    "If we want our Python code to run fast, we have to organize the sequence of operation in a smart way. In particular a very common case like calling an **if** command inside a for loop can make Python very slow. We have seen above how looping makes Python slow. One of the secrets that makes Python fast is to use smart indexing. To use indexing in practice in this case means to vectorize the command **if** and then to use these indexes to selectively operate on arrays. This might seem a terrible setback for Python programmers, however the great advantage of forcing the developer to do this operation is that the program will be written in a completely vectorized way from the start, therefore ready to be parallelized.\n",
    "\n",
    "Indexing and slicing in NumPy is a long topic, whose full coverage goes beyond the scopes of this book. To gain a full understanding of the possibilities offered by NumPy I recommend to follow one of the online free tutorials (e.g., https://docs.scipy.org/doc/numpy-dev/user/basics.indexing.html). I will cover here some main the features that we will use more often in this book, and explain in depth some important details on the memory management associated to ndarrays.\n",
    "\n",
    "Let us now dive into the main features that interest us. Given an array, e.g., **arr**, we can access the element n with square brackets **arr[n]** and we can slice the array extracting the elements between n and m with the command **arr[n:m]**, which will return m − n elements (comprising **arr[n]** and excluding **arr[m]**. It is very important to understand that even if we associate a name to the slice of arr, this is only a view, not a new array implying that the m − n elements are not copied in a new allocated chunk of memory. This means that by changing the sliced array you will change the initial data. Let us look at an example to clearly understand how this works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "secondArr=np.arange(20)\n",
    "secondArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sliceArr = secondArr[4:10]\n",
    "superslicearray = sliceArr\n",
    "sliceArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     4,      5,      6, 100000,      8,      9])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "superslicearray[3]=100000\n",
    "sliceArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([     0,      1,      2,      3,      4,      5,      6, 100000,\n",
       "            8,      9,     10,     11,     12,     13,     14,     15,\n",
       "           16,     17,     18,     19])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "secondArr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Who is familiar with other languages might be surprised by this behavior, and believe that when defining sliceArr Python should have copied the subset of second **Arr** data into a new array. The point is that NumPy has been designed to deal with very large datasets or numerical models, therefore it uses a policy of minimization of memory usage. For this reason, if one does not force NumPy to create a copy of the sliced data, it will simply generate a view of the already existing array. NumPy can be forced to create a separate new array by adding **.copy()** to the slice, e.g., in our case **sliceArr = secondArr[4:10].copy()**.\n",
    "\n",
    "Slicing is very flexible and allows omitting, for example, the first index (e.g., **arr[:10]**) or the last index (e.g., **arr[10:]**) of a slice, which implies that the slice reaches the end of the array. It is also possible to slice the array every k elements by indicating a third parameter in the slice (e.g., **arr[4:12:3]**), and also omitting the other parameters (e.g., **arr[::3]**). Negative indexes are also admitted, which means that counting starts from the last element, backward, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 11, 12, 13, 14])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "secondArr[10:-5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### N-Dimensional Indexing\n",
    "Indexing and slicing in more dimensions are just a recursive repetition of one-dimensional operations. In 2D, for example, arrays can be indexed either as **arr2d[n][m]** or, with the same effect, as **arr2d[n,m]**. The first index refers to the inner array, the second index to the outer array. For example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [ 8,  9, 10, 11],\n",
       "       [12, 13, 14, 15],\n",
       "       [16, 17, 18, 19]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr2d = np.arange(20)\n",
    "sliceArr = arr2d[4:10]\n",
    "arr2d=arr2d.reshape((5,4))\n",
    "arr2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sliceArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   1,   2,   3],\n",
       "       [  4,   5,   6, 100],\n",
       "       [  8,   9,  10,  11],\n",
       "       [ 12,  13,  14,  15],\n",
       "       [ 16,  17,  18,  19]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sliceArr[3]=100\n",
    "arr2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "secondArr[4*2+3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is very important to remember that the reshape command does not create a copy of the data, as well as slicing. The data remain stored in the memory as a one-dimensional array, regardless of the dimensions and shape of the array. The way in which this is done and how NumPy broadcasting operations remain extremely efficient is explained later, where strides are illustrated. Also a book that analyzes in greater detail how Python can deal with data is McKinney,W.(2012) Python for data analysis. Newton: O’Reilly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boolean Indexing\n",
    "\n",
    "Boolean indexing is the fastest and efficient way to select, access and operate on subsets of a NumPy arrays. Let us for example create a random 5 × 5 matrix (array) and select only the positive elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.22099398, -0.14879075, -1.19395346, -0.57670602,  0.64556606],\n",
       "       [ 0.32079202, -0.01872761,  0.96515051, -0.82389689, -1.10377444],\n",
       "       [ 0.00323964, -0.31459612,  0.47434386,  0.75628592,  1.3449736 ],\n",
       "       [-0.16521876, -0.31568834, -0.12364073,  0.70611395,  1.04736252],\n",
       "       [-0.59991713,  0.05634265,  1.14699918,  0.3175479 ,  0.46771736]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr2d = np.random.randn(5,5)\n",
    "arr2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False, False, False,  True],\n",
       "       [ True, False,  True, False, False],\n",
       "       [ True, False,  True,  True,  True],\n",
       "       [False, False, False,  True,  True],\n",
       "       [False,  True,  True,  True,  True]], dtype=bool)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr2d>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.64556606,  0.32079202,  0.96515051,  0.00323964,  0.47434386,\n",
       "        0.75628592,  1.3449736 ,  0.70611395,  1.04736252,  0.05634265,\n",
       "        1.14699918,  0.3175479 ,  0.46771736])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr2d[arr2d>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we did was to create a 5×5 array whose values were True when the elements were positive, and False in the opposite case. It was then possible to select only those elements. It is important to notice that the extracted elements have lost their 5 × 5 structure. This again results from the fact that Python stores every array, regardless of its shape, as a 1D array.\n",
    "\n",
    "This technique is normally used to operate on a certain subset of an array. For example if we desire to set to 0 all the negative elements of the above array, we can do it with one instruction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        ,  0.        ,  0.64556606],\n",
       "       [ 0.32079202,  0.        ,  0.96515051,  0.        ,  0.        ],\n",
       "       [ 0.00323964,  0.        ,  0.47434386,  0.75628592,  1.3449736 ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.70611395,  1.04736252],\n",
       "       [ 0.        ,  0.05634265,  1.14699918,  0.3175479 ,  0.46771736]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr2d[arr2d<0]=0\n",
    "arr2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to emphasize that besides compactness and elegance, this technique guarantees an enormous gain in speed. To quantify this advantage, we can compare the time necessary for a standard Python for loop with the Boolean indexing tool described above for a large 2000 × 2000 random array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr2d=np.random.randn(2000,2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.07 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "def setNegativeValuesToZero(n,m,a): \n",
    "    for i in np.arange(n):\n",
    "        for j in np.arange(m):\n",
    "            if a[i,j]<0:\n",
    "                a[i,j]=0\n",
    "%timeit -n1 -r1 setNegativeValuesToZero(2000,2000,arr2d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.9 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "arr2d = np.random.randn(2000,2000)\n",
    "%timeit -n1 -r1 arr2d[arr2d<0]=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we observe a gain of 2 orders of magnitude by using the NumPy indexing compared to standard Python loops. The message is now loud and clear: never use Python loops for large datasets and large numerical models, but always employ Python indexing/slicing features to achieve compiled code performance for speed and memory management. When not possible, rely on Cython, that we will study soon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transposing and Axis Rotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already encountered the function reshape, which allows to project a 1D array as a generic n-dimensional array. One operation that cannot be achieved by reshaping is however transposing, which corresponds to swapping axis. This is a very important function when operating on 2D and 3D numerical modeling, but it is also simply essential in order to calculate the inner product. For example, to calculate Xtranspose * X , one writes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.2046353 ,  0.85770689],\n",
       "       [-0.21520824, -1.2484946 ],\n",
       "       [ 1.04964441, -0.6121175 ],\n",
       "       [-0.3866603 , -0.17058125],\n",
       "       [-0.35273257, -1.26729852]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=10\n",
    "arr2d = np.random.randn(n)\n",
    "arr2d\n",
    "arr2d=arr2d.reshape(5,int(n/5))\n",
    "arr2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.87314064, -0.89406894],\n",
       "       [-0.89406894,  4.30423122]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr2d.T\n",
    "np.dot(arr2d.T,arr2d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8731406445538541"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(arr2d[:,0])**2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transposing, however, is not limited to swapping x and y axis. One can rotate axis as well. For example in 3D:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]],\n",
       "\n",
       "       [[12, 13, 14, 15],\n",
       "        [16, 17, 18, 19],\n",
       "        [20, 21, 22, 23]]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr3d = np.arange(2*3*4).reshape(2,3,4)\n",
    "arr3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3, 4)\n",
      "(4, 2, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  4,  8],\n",
       "        [12, 16, 20]],\n",
       "\n",
       "       [[ 1,  5,  9],\n",
       "        [13, 17, 21]],\n",
       "\n",
       "       [[ 2,  6, 10],\n",
       "        [14, 18, 22]],\n",
       "\n",
       "       [[ 3,  7, 11],\n",
       "        [15, 19, 23]]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr3d2 = arr3d.transpose((2,0,1)).copy()\n",
    "print(arr3d.shape)\n",
    "print(arr3d2.shape)\n",
    "arr3d[1,0,0]=1000\n",
    "arr3d2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transposing, as well as reshaping, is just a specific view of the entire array, therefore transposing will not create a new set of data, and when modifying the transposed of an array, one modifies the original array as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strides\n",
    "\n",
    "The technical details given here help to understand how NumPy deals with very large arrays minimizing memory occupation and maximizing access speed.\n",
    "\n",
    "It is important to emphasize that although an array can have many dimensions, the memory in our computer is structured in a purely sequential way, therefore ultimately the real structure of the array is one-dimensional, and every n-dimensional array will only be a specific view on that 1D array.\n",
    "\n",
    "NumPy is extraordinary powerful in managing n-dimensional arrays, different views, complex subsets, for example\n",
    "\n",
    "```python\n",
    "arr[arr*arr<1]. ```\n",
    "\n",
    "This power is based on the ability to directly address chunks of data by striding across the\n",
    "memory and zooming into small blocks of memory. For example, let us take a random 100 × 100 × 100 array of np.float64 data, equivalent to a 1D array of one million elements, occupying 8 bytes each. A block within the array can be extracted in microseconds, almost regardless to the size of the block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.18724565, -1.17847098, -0.17901848, ...,  0.31548821,\n",
       "          1.52386289,  1.30550334],\n",
       "        [ 0.03921961, -1.14513095,  1.08349513, ..., -0.91107397,\n",
       "          0.5990501 , -0.0095132 ],\n",
       "        [-1.03494619, -0.34494331,  1.3066751 , ...,  0.44352633,\n",
       "         -2.02974536, -0.41618236],\n",
       "        ..., \n",
       "        [ 0.18847539, -0.32793023, -0.06932623, ..., -1.43874036,\n",
       "         -0.05679142,  1.04636072],\n",
       "        [ 0.64027859, -0.15175745, -0.3156143 , ...,  1.00759914,\n",
       "         -0.29944952, -0.2369739 ],\n",
       "        [-1.2539037 , -2.43883094,  0.81398595, ..., -0.48610907,\n",
       "         -0.51769285,  0.10317585]],\n",
       "\n",
       "       [[ 1.69603699,  1.00736172,  0.10801974, ..., -1.29719681,\n",
       "         -0.33559794, -0.46042177],\n",
       "        [-1.4134579 , -0.21276452,  0.81306398, ...,  0.83519248,\n",
       "          0.32448463,  1.213974  ],\n",
       "        [-2.53249634, -0.1706863 ,  1.2617902 , ..., -0.64415962,\n",
       "         -1.01044812,  1.12183039],\n",
       "        ..., \n",
       "        [ 0.43750043, -0.59698592, -0.31926476, ...,  0.35626372,\n",
       "          0.49650653, -0.08276614],\n",
       "        [-0.41357803,  0.20403411, -0.38415275, ...,  0.76050882,\n",
       "          1.25632425,  1.52498053],\n",
       "        [-0.15943128,  2.06170838, -1.16828532, ..., -1.58786599,\n",
       "         -0.35736188,  0.14931724]],\n",
       "\n",
       "       [[-0.37470792,  0.44622442, -1.49540694, ...,  0.68394716,\n",
       "          0.30223809, -1.33415385],\n",
       "        [-1.0557444 , -0.11103583,  0.5124893 , ...,  0.42224799,\n",
       "          0.36123396, -0.68191915],\n",
       "        [ 1.53788495, -0.8110327 ,  2.14331587, ...,  1.04927217,\n",
       "          0.72678421,  1.42814181],\n",
       "        ..., \n",
       "        [-1.3521895 ,  0.16395182, -0.90955055, ..., -0.1918091 ,\n",
       "         -1.52656673,  0.16903883],\n",
       "        [ 0.91777817, -0.33608333, -1.75245412, ..., -0.44640046,\n",
       "          0.75954357, -0.78522054],\n",
       "        [-1.99344618,  0.80178082, -0.12483909, ...,  0.29330599,\n",
       "          0.80813022,  0.44455524]],\n",
       "\n",
       "       ..., \n",
       "       [[-0.80547591,  0.81256278, -0.73820938, ...,  0.12082891,\n",
       "         -0.24213823,  0.19195229],\n",
       "        [-0.67311147, -0.45091584, -1.32697256, ..., -1.2631246 ,\n",
       "          0.62080853,  0.99280121],\n",
       "        [ 1.23456585, -1.53620494,  0.26785183, ..., -0.1858177 ,\n",
       "          0.03890219,  0.7031548 ],\n",
       "        ..., \n",
       "        [ 1.09277168,  0.97827766,  0.33196078, ..., -0.12866418,\n",
       "         -0.1493553 ,  0.57210103],\n",
       "        [ 2.63984892, -1.55026499,  0.7441563 , ...,  2.04156435,\n",
       "          0.58100699,  0.06014456],\n",
       "        [-0.17550217,  1.48199999,  0.90514197, ...,  0.43274279,\n",
       "          1.69195252, -0.50465659]],\n",
       "\n",
       "       [[ 0.29223542,  0.54317518,  1.71802927, ..., -0.53903948,\n",
       "          0.34291725,  0.32306956],\n",
       "        [-0.34093642,  0.06200793, -0.41667712, ..., -0.55989491,\n",
       "         -1.2571424 , -0.09117052],\n",
       "        [-0.02049319, -1.08105372, -0.06964258, ...,  0.75997703,\n",
       "          0.43949913, -0.72246016],\n",
       "        ..., \n",
       "        [ 0.07656126, -0.7712067 ,  1.15540613, ...,  0.19676105,\n",
       "         -0.40874781,  1.42355762],\n",
       "        [-0.04066521, -0.33991882,  0.53505545, ...,  0.40963138,\n",
       "          0.80379394,  0.3992602 ],\n",
       "        [-2.04427806, -1.09793084, -1.48858239, ...,  0.35391819,\n",
       "         -0.60901059,  0.76382574]],\n",
       "\n",
       "       [[-0.28117053, -0.28491626, -1.71324977, ..., -0.85743644,\n",
       "          0.84989771, -1.14640795],\n",
       "        [ 0.31160414,  2.11303651, -0.81290836, ...,  0.18325345,\n",
       "          0.58576073, -0.44718079],\n",
       "        [ 0.85763618,  0.21406062,  0.62029103, ..., -0.11018449,\n",
       "         -0.64081657, -0.47037994],\n",
       "        ..., \n",
       "        [-0.35062165, -0.12849063, -1.30952006, ...,  1.05033429,\n",
       "          1.30611244, -0.17473676],\n",
       "        [-0.66257276, -1.27159755, -1.28118509, ..., -0.55538489,\n",
       "         -1.2622294 , -0.09434889],\n",
       "        [ 0.33080135,  1.06039536, -0.37605778, ...,  0.20759099,\n",
       "          0.95433949,  0.76911627]]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randn(100,100,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.1 µs ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n1 -r1 newArray=arr3d[45:55,45:55,45:55].copy() #small block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.9 µs ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n1 -r1 newArray2=arr3d[15:85,15:85,15:85].copy() #large block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we operate on the subset of the array however the operational time increases with the size of the block, although not in a proportional way. For example, to set the values of the subset to zero we need about 20 times more time for a subset that is over 300 times greater:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.06 µs ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n1 -r1 arr3d[45:55,45:55,45:55]=0 #small block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.17 µs ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n1 -r1 arr3d[15:85,15:85,15:85]=0 #large block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy accesses n-dimensional arrays and its slices as fast as one-dimensional arrays. To understand how this is achieved, let us consider, for example an array a of 32000 integers and then create a reshaped three-dimensional 20 × 40 × 40 version assigned to b. In our case a is composed by 64-bit (8 bytes) integers, which means that one needs to proceed 8 bytes forward to access the next element along the first axis. The size of every element can be also in general assessed with a.itemsize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a=np.arange(32000)\n",
    "b=a.reshape(20,40,40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 8\n"
     ]
    }
   ],
   "source": [
    "print(a.itemsize,b.itemsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will be stored in memory in a buffer that contains 32000 ascending integers from 0 to 31999. As we have seen before a and b are stored in the same memory block. The way in which NumPy differentiates how to operate on them is by characterizing them by their different strides. Strides are tuples of bytes to step in each dimension when traversing an array. In practice they are the offset in bytes between an element and the neighboring one in every direction. Strides are shown explicitly using the instruction arr.strides:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 40, 40) (12800, 320, 8)\n",
      "320 12800\n"
     ]
    }
   ],
   "source": [
    "print(b.shape,b.strides)\n",
    "print(8*40,8*40*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.strides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last number, 8, of the strides refers to the size of each element in the array, i.e., it is always the itemsize. The other numbers refer to the number of bytes forward necessary to access the next element along the other axes. The total number of bytes is called offset and is calculated as offset = sum(indexes * a.strides). For example, for the initial array a[n] every element is accessed at the position \n",
    "```python\n",
    "offset = n*a.strides[0]\n",
    "```\n",
    ", while b[i,j,k] is accessed calculating its associated memory offset as \n",
    "```python\n",
    "offset = i*b.strides[0]+j*b.strides[1]+k*b.strides[2]\n",
    "```\n",
    "in bytes. To obtain the element location one has to divide by b.itemsize. For example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3324"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3324.0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2*b.strides[0]+3*b.strides[1]+4*b.strides[2])/b.itemsize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Vector Product\n",
    "\n",
    "The inner product, np.dot() in NumPy, is the most common operation between arrays. It is equivalent to the inner product between 1-D arrays or to matrix multiplication between 2D arrays. It is defined on n-dimensional arrays as the sum product over the last axis of the first array and the second-to-last of the second array. For example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2476189485264719"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(np.random.rand(1000),b=np.random.rand(1000))/1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "will give you a number close to 0.25, since np.random.rand() is a uniformly extracted random number between 0 and 1. Similarly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.24916199,  0.21980623,  0.23265348, ...,  0.19299233,\n",
       "         0.22978476,  0.21044342],\n",
       "       [ 0.2669618 ,  0.23955759,  0.25529797, ...,  0.20856689,\n",
       "         0.24533665,  0.23089471],\n",
       "       [ 0.32034683,  0.26741572,  0.2567161 , ...,  0.23115299,\n",
       "         0.26659589,  0.25110512],\n",
       "       ..., \n",
       "       [ 0.2935968 ,  0.24545271,  0.26713809, ...,  0.2367511 ,\n",
       "         0.2666687 ,  0.24843038],\n",
       "       [ 0.2874005 ,  0.25065884,  0.23514158, ...,  0.21083831,\n",
       "         0.24390513,  0.22585265],\n",
       "       [ 0.27790006,  0.25558342,  0.24748777, ...,  0.22732223,\n",
       "         0.25628107,  0.24053523]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(np.random.rand(100,100),b=np.random.rand(100,100))/100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "will result in a 100 × 100 matrix of numbers normally distributed around 0.25. \n",
    "\n",
    "Outer products are called by np.outer() and are an easy way to create an x, y regular mesh:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=np.arange(0,11,1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=np.ones(11)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0.,    1.,    4.,    9.,   16.,   25.,   36.,   49.,   64.,\n",
       "          81.,  100.],\n",
       "       [   1.,    0.,    1.,    4.,    9.,   16.,   25.,   36.,   49.,\n",
       "          64.,   81.],\n",
       "       [   4.,    1.,    0.,    1.,    4.,    9.,   16.,   25.,   36.,\n",
       "          49.,   64.],\n",
       "       [   9.,    4.,    1.,    0.,    1.,    4.,    9.,   16.,   25.,\n",
       "          36.,   49.],\n",
       "       [  16.,    9.,    4.,    1.,    0.,    1.,    4.,    9.,   16.,\n",
       "          25.,   36.],\n",
       "       [  25.,   16.,    9.,    4.,    1.,    0.,    1.,    4.,    9.,\n",
       "          16.,   25.],\n",
       "       [  36.,   25.,   16.,    9.,    4.,    1.,    0.,    1.,    4.,\n",
       "           9.,   16.],\n",
       "       [  49.,   36.,   25.,   16.,    9.,    4.,    1.,    0.,    1.,\n",
       "           4.,    9.],\n",
       "       [  64.,   49.,   36.,   25.,   16.,    9.,    4.,    1.,    0.,\n",
       "           1.,    4.],\n",
       "       [  81.,   64.,   49.,   36.,   25.,   16.,    9.,    4.,    1.,\n",
       "           0.,    1.],\n",
       "       [ 100.,   81.,   64.,   49.,   36.,   25.,   16.,    9.,    4.,\n",
       "           1.,    0.]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=np.outer(a,b)\n",
    "x\n",
    "x2=np.outer(b,a)\n",
    "x2\n",
    "(x-x2)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbd2885b2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "y=np.outer(b,a)\n",
    "plt.plot(x,y,'o');plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy allows composing large arrays combining blocks of one array scaled by another. This operation is called Kronecker product, and we will intensively use it to build large operators for two-dimensional continuum mechanics. For example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  0.,  0.,  0.,  0.],\n",
       "       [ 1.,  1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  1.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  1.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  1.]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.kron(np.eye(3), np.ones((2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Algebra\n",
    "\n",
    "All the linear algebra tools that we will need are already efficiently implemented through the standard optimized ATLAS LAPACK and BLAS libraries. Ultimately all linear algebra routines expect to operate on a 2-dimensional array. There is also a matrix type in NumPy but its use is discouraged since it is possible to obtain the same result by using arrays only.\n",
    "\n",
    "Linear algebra has many subprograms that run routines for decompositions such as Cholesky, QR and Singular Value. They can be very important for many problems, however they do not apply for the problems that we will address in this volume. The interested reader can refer to the regularly updated SciPy manual at http://docs.scipy.org/doc/numpy/reference/routines.linalg.html. \n",
    "\n",
    "Linear algebra (LA) routines are accessed through the module numpy.linalg:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy.linalg as linalg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An often employed tool is linalg.norm() both for calculating the size of a 1D (vector) and 2D (matrix) arrays. Norm, that is just the square root of the sum of the square of all the elements of a n-dimensional array, could be also calculated by the definition, but the numpy.linalg implementation can be one order of magnitude as more efficient. Let us for example benchmark the calculation of a 100 × 100 array norm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(201, 201)\n"
     ]
    }
   ],
   "source": [
    "a=np.arange(-100,101,1)\n",
    "b=np.arange(201)\n",
    "x=np.outer(a,b)\n",
    "\n",
    "x\n",
    "#normVectorized=np.sqrt(sum(sum(x**2)))\n",
    "#normVectorizedctorized\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "277 µs ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1 -r1 linalg.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342 µs ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 1 -r1 np.sqrt(sum(sum(x**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determinants are often employed in linear algebra because they are related to the invertibility of a matrix, and on whether the associated linear system of equations is solvable (a smaller determinant can indicate that some eigenvalues are close to zero, which makes inversion harder). However, to calculate the determinant of extremely large 2D arrays as we will often do in this volume is computationally so demanding that we will do it only for small problems. Let us calculate the determinant of few random matrices, 10 × 10 and 100 × 100, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.05203532, -0.15953656,  0.0205167 ,  0.01746048,  0.03476215,\n",
       "        0.03132063, -0.00255587, -0.02087137,  0.00216041,  0.00059872])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dets=np.zeros(10)\n",
    "for i in np.arange(10): dets[i]=linalg.det(np.random.rand(10,10))\n",
    "dets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -8.65506401e+24,  -2.09022551e+23,  -4.53402053e+24,\n",
       "        -3.16088830e+24,  -1.23824174e+25,   1.53921226e+24,\n",
       "        -1.96400623e+25,  -1.67194879e+24,   2.49299685e+25,\n",
       "         4.48665016e+24])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in np.arange(10): dets[i]=linalg.det(np.random.rand(100,100))\n",
    "dets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cython\n",
    "\n",
    "There are situations in which a simple and straightforward NumPy solution does not exist or can be very difficult to implement. We will see some examples in the last, advanced part. When we are in this situation, it is first of all important to verify first whether this lack of vectorization makes our code sensibly slower. Since this is often the case, a powerful solution has been created by the authors of the parts that compose the Python Scientific Environment, which is called Cython.\n",
    "\n",
    "The most recent updates and documentation for Cython are available at the address cython.org). Cython is based on Pyrex, library that allowed to extend Python with C functions. Recently, however Cython developers went beyond and created an extended language where codes written in Python are optimized and compiled just at the moment of running the Python program. In other words, while the Python language is interpreted, the computer will on-the-fly compile the parts of your code written in Python in special Cython files. Still they will be written in Python, which means that the user does not need to learn a new, more challenging language, such as C. The result is a superior language, only slightly more complex than Python, that combines the best of the two worlds, C and Python.\n",
    "\n",
    "The main addition of Python to Cython are static variables. These are variables for which type and space in memory is predefined by the programmer. The advantage of using them is that the Python parser does not need to understand how to interpret them on the fly (one of the most original but computationally most inefficient characteristic of Python) while will straightaway compile and execute the fastest possible way to run the code. In practice, Cython is simply Python code with variables defined using C data types. Typically it consists of one or few functions that require being compiled with explicitly defined types and called in our code. Since the performance of Cython code are nearly equal to an equivalent C-code, but are much easier written, Cython is the definitive tool that makes prototyping in Python the easy and powerful programming tool that every scientist dreams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cython in iPython\n",
    "\n",
    "Let us look at some examples of how it works, starting with iPython. I will use IPython 4.0.1. Different versions of IPython can make use of other magic commands.\n",
    "\n",
    "In iPython first you have to load the Cython library. This can be done with the magic command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Immediately after, one can use both the magic commands %cython, and %%cython, the first to run external Cython files, and the second to run a Cython cell. Let us see how we could have implemented the function setNegativeValuesToZero that we intro- duced earlier in the chapter. A first attempt would be to simply rewrite that function, just adding that n, m, i and l are integer types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "def setNegativeValuesToZero(int n,int m, a):\n",
    "    cdef int i, j\n",
    "    for i in range(n):\n",
    "        for j in range(m): \n",
    "            if a[i,j]<0:\n",
    "                a[i,j]=0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one reads on line 2, the type declaration is done simply by using the instruction cdef, then followed by the standard static C type declaration. Notice also that I replace np.arange with range, since this is the compiled version where loops are compiled. Basically, besides the addition of the int, i.e., integer, inside the call, this is exactly the same function introduced earlier. One can test its performance with the same random 2000 × 2000 array finding an improvement of a factor two compared to the pure Python version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 2000)\n",
      "1.65 s ± 4.09 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "arr2d=np.random.randn(2000,2000)\n",
    "print(arr2d.shape)\n",
    "%timeit setNegativeValuesToZero(2000,2000,arr2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can one do better? Yes, but it requires some more work. I show here a version that performs practically exactly the same as the NumPy one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "cimport numpy as np\n",
    "def setNegativeValuesToZero(int n, int m, np.ndarray[double, ndim=2] a):\n",
    "    cdef int i, j\n",
    "    for i in range(n):\n",
    "        for j in range(m): \n",
    "            if a[i,j]<0:\n",
    "                a[i,j]=0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one observes here, it is necessary to add one more line and change one type. The first is the import of numerical python within the Cython framework. This allows to set the type of the NumPy array a, which in turn allows Cython to accelerate its process. Once these two little modifications are done, one obtains the striking result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 4.60 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "10.1 ms ± 8.35 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "arr2d=np.random.randn(2000,2000)\n",
    "%timeit -n 1 setNegativeValuesToZero(2000,2000,arr2d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is very close to NumPy, and in this case slightly better.\n",
    "A good Python programmer, although not Cython expert, will need only ten minutes to figure out how to modify a routine to make it ready for Cython, however for the novice programmer to go through the debugging effort that compiled programs require can be quite challenging. For this reason I recommend always using the straightforward NumPy libraries whenever necessary, and rely on Cython only when really necessary. The many more details that one has to know in order to program Cython are available in the excellent recent book Cython - A Guide for Python Programmers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going Parallel: mpi4py and PETSc4py\n",
    "\n",
    "mpi4py is a simple but powerful interface that allows to write MPI software natively in Python. This is however not the only option, and other projects exist such as pyMPI, that is also very simple but does not support numerical python arrays, and pypar.\n",
    "\n",
    "mpi4py is presently a translation of standard MPI-2 bindings for C++ to Python. There are two categories of variables that can be passed from one processor to the other: (i) the standard Python objects, and (ii) the NumPy arrays. Because the memory configuration of the first kind is not compact nor standard, mpi4py achieves maximum performance by building binary representations of these objects that are then sent to other processors. Clearly building this binary representation limits its use and can create a serious overhead for very large systems or data. Furthermore this process, called pickling, can also require extra memory and it needs to be tested on every machine.\n",
    "\n",
    "In order to use mpi4py, one has to install first MPI independently from the Python installation. Presently, on the windows platform, one has to install OpenMPI through Cygwin. Once this has been done, one can install mpi4py in Cygwin, or any other Linux system as well as the OSX Terminal, simply with the command pip install mpi4py. If using Anaconda the command conda install -c anaconda mpi4py=2.0.0 will add mpi4py to the Anaconda installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mpi4py'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-3e86e3513d56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmpi4py\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMPI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcomm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMPI\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOMM_WORLD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGet_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mpi4py'"
     ]
    }
   ],
   "source": [
    "from mpi4py import MPI \n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "if rank == 0:\n",
    "    data = {'a': 0.1, 'b': 1, 'c':'house', 'd':1.0e100} \n",
    "    comm.send(data, dest=1, tag=111)\n",
    "    print('data sent from',rank,' :',data)\n",
    "elif rank == 1:\n",
    "    data = comm.recv(source=0, tag=111) \n",
    "    print('data received from',rank,' :',data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
